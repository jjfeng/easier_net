{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6edf4d7",
   "metadata": {},
   "source": [
    "This tutorial will cover how to run an EASIER-net model, with a regression and classification example. \n",
    "\n",
    "We will also how you can integrate GridSearchCV from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from easier_net import EasierNetEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dbc116",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c29b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some fake data\n",
    "def make_data(n_samples, n_features=20):\n",
    "    x = np.random.rand(n_samples,n_features)\n",
    "    beta = np.ones(n_features).reshape((-1,1))\n",
    "    eps = np.random.randn(n_samples) * 0.1\n",
    "    y = x @ beta + eps\n",
    "    return x,y\n",
    "\n",
    "np.random.seed(0)\n",
    "train_x, train_y = make_data(1000)\n",
    "test_x, test_y = make_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1024f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train an easier net\n",
    "e_net = EasierNetEstimator(\n",
    "    n_estimators=2,\n",
    "    input_filter_layer=True,\n",
    "    n_layers=3,\n",
    "    n_hidden=20,\n",
    "    full_tree_pen=0.1,\n",
    "    input_pen=0.01,\n",
    "    batch_size=100,\n",
    "    num_classes=0,\n",
    "    weight=[],\n",
    "    max_iters=800,\n",
    "    max_prox_iters=20)\n",
    "\n",
    "e_net.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test data\n",
    "predictions = e_net.predict(test_x)\n",
    "mse = np.mean(np.power(predictions - test_y, 2))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb8a94",
   "metadata": {},
   "source": [
    "##### Grid Search for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738039bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV\n",
    "# Set parameter grid\n",
    "param_grid = [\n",
    "    {'n_estimators': [5], 'n_layers': [5], 'n_hidden': [100], 'input_pen': [0.01, 0.1, 1], \n",
    "     'full_tree_pen': [0.01, 0.1, 1], 'max_iters': [100], 'max_prox_iters': [50]},\n",
    "]\n",
    "\n",
    "e_net_gridsearch = GridSearchCV(\n",
    "    estimator = e_net, \n",
    "    param_grid = param_grid, \n",
    "    cv = 5).fit(train_x, train_y)\n",
    "\n",
    "# Return predictions with the estimator that has the best parameters\n",
    "y_pred = e_net_gridsearch.predict(test_x)\n",
    "\n",
    "# Return score on given test data\n",
    "e_net_gridsearch.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5653c69",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e7f5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_data(n_samples, num_classes, n_features=20): \n",
    "    x = np.random.rand(n_samples,n_features)\n",
    "    beta = np.zeros(n_features)\n",
    "    beta[:n_features//2] = 1\n",
    "    prob_y = 1/(1 + np.exp(-np.matmul(x, beta)))\n",
    "    y = np.random.binomial(n=1, p=prob_y).reshape((-1,1))\n",
    "    return x,y\n",
    "\n",
    "np.random.seed(0)\n",
    "cls_train_x, cls_train_y = make_class_data(1000, 2)\n",
    "cls_test_x, cls_test_y = make_class_data(1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be8c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss: 19.856063842773438 empirical: 0.6230040788650513\n",
      "[100] loss: 0.2376309633255005 empirical: 0.07095792144536972\n",
      "[200] loss: 0.20347991585731506 empirical: 0.10476058721542358\n",
      "[300] loss: 0.20324358344078064 empirical: 0.1298779845237732\n",
      "[400] loss: 0.15985345840454102 empirical: 0.09884363412857056\n",
      "[500] loss: 0.12062814831733704 empirical: 0.0608196035027504\n",
      "[600] loss: 0.08263266086578369 empirical: 0.023281900212168694\n",
      "[700] loss: 0.1586335301399231 empirical: 0.09824790805578232\n",
      "[prox 0] loss: 0.10962861776351929 empirical: 0.07200349867343903\n",
      "[0] loss: 19.381196975708008 empirical: 0.7526767253875732\n",
      "[100] loss: 0.2602955996990204 empirical: 0.07801123708486557\n",
      "[200] loss: 0.18761777877807617 empirical: 0.06696801632642746\n",
      "[300] loss: 0.13778820633888245 empirical: 0.059880439192056656\n",
      "[400] loss: 0.135111466050148 empirical: 0.06188954412937164\n",
      "[500] loss: 0.19520701467990875 empirical: 0.13544189929962158\n",
      "[600] loss: 0.08348388969898224 empirical: 0.02335783652961254\n",
      "[700] loss: 0.19651828706264496 empirical: 0.13573883473873138\n",
      "[prox 0] loss: 0.10962189733982086 empirical: 0.07200401276350021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<easier_net.easier_net.EasierNetEstimator at 0x16cc34370>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an easier net\n",
    "cls_easier_net = EasierNetEstimator(\n",
    "    n_estimators=2,\n",
    "    input_filter_layer=True,\n",
    "    n_layers=3,\n",
    "    n_hidden=20,\n",
    "    full_tree_pen=0.1,\n",
    "    input_pen=0.01,\n",
    "    batch_size=100,\n",
    "    num_classes=2, #set this to however many class you have in your dataset\n",
    "    weight=[1,1],\n",
    "    max_iters=800,\n",
    "    max_prox_iters=20)\n",
    "\n",
    "cls_easier_net.fit(cls_train_x, cls_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "977aa2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049476746\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test data\n",
    "predict_log_proba = np.log(cls_easier_net.predict_proba(cls_test_x))\n",
    "neg_log_lik = -np.mean(predict_log_proba[np.arange(cls_test_y.size),cls_test_y.flatten()])\n",
    "print(neg_log_lik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4084e7f",
   "metadata": {},
   "source": [
    "##### Grid Search for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV\n",
    "# Set parameter grid\n",
    "param_grid = [\n",
    "    {'n_estimators': [5], 'n_layers': [5], 'n_hidden': [100], 'input_pen': [0.01, 0.1, 1], \n",
    "     'full_tree_pen': [0.01, 0.1, 1], 'max_iters': [100], 'max_prox_iters': [50]},\n",
    "]\n",
    "\n",
    "cls_e_net_gridsearch = GridSearchCV(\n",
    "    estimator = cls_easier_net, \n",
    "    param_grid = param_grid, \n",
    "    cv = 5).fit(cls_train_x, cls_train_y)\n",
    "\n",
    "# Return predicted log probabilities for given test data\n",
    "y_pred_log_proba = cls_e_net_gridsearch.predict_log_proba(cls_test_x)\n",
    "\n",
    "# Return score on given test data\n",
    "cls_e_net_gridsearch.score(cls_test_x, cls_test_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easier_venv",
   "language": "python",
   "name": "easier_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
